% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estimate_propensity_NNET.R
\name{estimate_propensity_nnet}
\alias{estimate_propensity_nnet}
\title{Estimate Propensity Scores using a Single-Layer Neural Network}
\usage{
estimate_propensity_nnet(
  X_train,
  Z_train,
  X_test = NULL,
  size = 10,
  decay = 0.01,
  maxit = 200,
  verbose = FALSE
)
}
\arguments{
\item{X_train}{A numeric matrix or data frame of predictor variables for the training set.}

\item{Z_train}{A numeric vector of binary treatment assignments (0 or 1) for the training set.}

\item{X_test}{(Optional) A numeric matrix or data frame of predictor variables for the test set.
Must have the same columns in the same order as \code{X_train}.}

\item{size}{Number of neurons (units) in the single hidden layer. This is the primary parameter
for controlling model complexity. Default is 10.}

\item{decay}{Weight decay parameter for regularization. This helps prevent overfitting by
penalizing large weights. Increase for stronger regularization. Default is 0.01.}

\item{maxit}{Maximum number of iterations for training. Default is 200.}

\item{verbose}{Logical. If \code{TRUE}, training progress information is printed. Default is \code{FALSE}.}
}
\value{
A list containing:
\item{train}{A numeric vector of estimated propensity scores for the \code{X_train} data.}
\item{test}{A numeric vector of estimated propensity scores for the \code{X_test} data. Returns \code{NULL} if \code{X_test} is not provided.}
}
\description{
Fits a standard, single-hidden-layer feed-forward neural network to model the
probability of treatment assignment (propensity score), P(Z=1 | X).

This function uses the R-native \strong{\code{nnet}} package, avoiding external Python dependencies.
While highly stable, it is less flexible than modern deep learning frameworks like Keras,
as it is limited to one hidden layer.
}
\details{
This function requires the \code{nnet} package. Input data \code{X_train} is automatically scaled
to the \link{0, 1} range, which is generally recommended for \code{nnet}. The treatment variable \code{Z_train}
is converted to a factor for classification.
}
\examples{
\dontrun{
# Generate synthetic data
set.seed(123)
n <- 500
p <- 5
X <- matrix(rnorm(n * p), ncol = p)
true_propensity <- pnorm(-0.5 + X[,1] + 0.5 * X[,2]^2)
Z <- rbinom(n, 1, true_propensity)

# Split data
train_idx <- sample(1:n, 400)
X_train <- X[train_idx, ]
Z_train <- Z[train_idx]
X_test <- X[-train_idx, ]

# Estimate propensity scores using nnet
nnet_scores <- estimate_propensity_nnet(
  X_train = X_train,
  Z_train = Z_train,
  X_test = X_test,
  size = 8, # Number of neurons in the hidden layer
  decay = 0.1
)

# View a summary of the estimated scores
summary(nnet_scores$train)
}
}
